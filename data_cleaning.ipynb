{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import chardet\n",
    "import re\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loaded from http://www2.informatik.uni-freiburg.de/~cziegler/BX/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USERS cleaning:\n",
    "- estimate encoding here since its smaller database that still contains text\n",
    "- remove outliers from age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISO-8859-1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get encoding\n",
    "data_path = os.path.join(\"data_dump\", \"BX-Users.csv\")\n",
    "rawdata = open(data_path, 'rb').read()\n",
    "result = chardet.detect(rawdata)\n",
    "result['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278853</th>\n",
       "      <td>278854</td>\n",
       "      <td>portland, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278854</th>\n",
       "      <td>278855</td>\n",
       "      <td>tacoma, washington, united kingdom</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278855</th>\n",
       "      <td>278856</td>\n",
       "      <td>brampton, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278856</th>\n",
       "      <td>278857</td>\n",
       "      <td>knoxville, tennessee, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278857</th>\n",
       "      <td>278858</td>\n",
       "      <td>dublin, n/a, ireland</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278858 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_ID                            Location   Age\n",
       "0             1                  nyc, new york, usa   NaN\n",
       "1             2           stockton, california, usa  18.0\n",
       "2             3     moscow, yukon territory, russia   NaN\n",
       "3             4           porto, v.n.gaia, portugal  17.0\n",
       "4             5  farnborough, hants, united kingdom   NaN\n",
       "...         ...                                 ...   ...\n",
       "278853   278854               portland, oregon, usa   NaN\n",
       "278854   278855  tacoma, washington, united kingdom  50.0\n",
       "278855   278856           brampton, ontario, canada   NaN\n",
       "278856   278857           knoxville, tennessee, usa   NaN\n",
       "278857   278858                dublin, n/a, ireland   NaN\n",
       "\n",
       "[278858 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data_dump\", \"BX-Users.csv\")\n",
    "users = pd.read_csv(data_path, encoding=\"ISO-8859-1\", sep=\";\")\n",
    "users.rename(columns={\"User-ID\": \"user_ID\"}, inplace=True)\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_ID       int64\n",
      "Location     object\n",
      "Age         float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "user_ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(users.dtypes)\n",
    "print(\"\\n\")\n",
    "print(users.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers\n",
    "users = users.loc[(users[\"Age\"] > 7) & (users[\"Age\"] < 90), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RATINGS cleaning:\n",
    "- keep only users with more than 3 ratings (otherwise could be difficult to estimate pattern in preference) and keep only users with less than 1000 ratings (there is an user with 12000 ratings so some users_IDs might be rating aggregators or sth, 1000 seems like a plausible number, like in last ten years read 2 books per week) but both numbers are arbitrary and should be part of pipeline (like try a few options and evaluate on a sample)\n",
    "- 40% of ratings are explicit, 60% implicit so we can’t discard  either group therefore for now implicit are converted to explicit with median value (if they bought the book, this is the most probable value of their reaction to it), but might change all to implicit in later analysis, this choice all implicit vs. all explicit should be also part of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149775</th>\n",
       "      <td>276704</td>\n",
       "      <td>1563526298</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149776</th>\n",
       "      <td>276706</td>\n",
       "      <td>0679447156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149777</th>\n",
       "      <td>276709</td>\n",
       "      <td>0515107662</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149778</th>\n",
       "      <td>276721</td>\n",
       "      <td>0590442449</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149779</th>\n",
       "      <td>276723</td>\n",
       "      <td>05162443314</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1149780 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_ID         ISBN  rating\n",
       "0         276725   034545104X       0\n",
       "1         276726   0155061224       5\n",
       "2         276727   0446520802       0\n",
       "3         276729   052165615X       3\n",
       "4         276729   0521795028       6\n",
       "...          ...          ...     ...\n",
       "1149775   276704   1563526298       9\n",
       "1149776   276706   0679447156       0\n",
       "1149777   276709   0515107662      10\n",
       "1149778   276721   0590442449      10\n",
       "1149779   276723  05162443314       8\n",
       "\n",
       "[1149780 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data_dump\", \"BX-Book-Ratings.csv\")\n",
    "ratings = pd.read_csv(data_path, encoding=\"ISO-8859-1\", sep=\";\")\n",
    "ratings.rename(columns = {'User-ID': \"user_ID\", \"Book-Rating\": \"rating\"}, inplace=True)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_ID     int64\n",
      "ISBN       object\n",
      "rating      int64\n",
      "dtype: object\n",
      "\n",
      "\n",
      "user_ID    0\n",
      "ISBN       0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ratings.dtypes)\n",
    "print(\"\\n\")\n",
    "print(ratings.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove users with not enough or too much ratings\n",
    "rating_counts = ratings[[\"user_ID\", \"rating\"]].groupby(\"user_ID\").count().reset_index().sort_values(\"rating\", ascending=False)\n",
    "ratings = ratings.loc[ratings[\"user_ID\"].isin(rating_counts.loc[(rating_counts[\"rating\"] > 3) & (rating_counts[\"rating\"] < 1000), \"user_ID\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     502187\n",
      "8      76466\n",
      "7      58165\n",
      "10     57732\n",
      "9      49350\n",
      "5      37867\n",
      "6      28361\n",
      "4       6754\n",
      "3       4508\n",
      "2       2053\n",
      "1       1192\n",
      "Name: rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ratings[\"rating\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3910190569160901\n"
     ]
    }
   ],
   "source": [
    "# how many explicit ratings?\n",
    "print(ratings.loc[ratings[\"rating\"]!=0,\"rating\"].count()/ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.loc[ratings[\"rating\"]!=0,\"rating\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elena\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# impute implicit with median explicit\n",
    "ratings.loc[ratings[\"rating\"]==0,\"rating\"] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     578653\n",
       "7      58165\n",
       "10     57732\n",
       "9      49350\n",
       "5      37867\n",
       "6      28361\n",
       "4       6754\n",
       "3       4508\n",
       "2       2053\n",
       "1       1192\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOOKS cleaning\n",
    "- about 20 books couldn't be parsed, problem in title so I made simple custom parser \n",
    "- csv reader has problem only when number of columns is higher than expected, so in 3 cases the number was lower (empty last column), these were duplicates so they were dropped\n",
    "- still some missing values but they are not a problem\n",
    "- some titles have multiple authors (up to 27) so title is not unique identifier \n",
    "- some popular titles have multiple ISBN (probably different editions and reprints) so ISBN can't be used for recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6452: expected 8 fields, saw 9\\nSkipping line 43667: expected 8 fields, saw 10\\nSkipping line 51751: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 92038: expected 8 fields, saw 9\\nSkipping line 104319: expected 8 fields, saw 9\\nSkipping line 121768: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 144058: expected 8 fields, saw 9\\nSkipping line 150789: expected 8 fields, saw 9\\nSkipping line 157128: expected 8 fields, saw 9\\nSkipping line 180189: expected 8 fields, saw 9\\nSkipping line 185738: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 209388: expected 8 fields, saw 9\\nSkipping line 220626: expected 8 fields, saw 9\\nSkipping line 227933: expected 8 fields, saw 11\\nSkipping line 228957: expected 8 fields, saw 10\\nSkipping line 245933: expected 8 fields, saw 9\\nSkipping line 251296: expected 8 fields, saw 9\\nSkipping line 259941: expected 8 fields, saw 9\\nSkipping line 261529: expected 8 fields, saw 9\\n'\n",
      "C:\\Users\\Elena\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3418: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url1</th>\n",
       "      <th>url2</th>\n",
       "      <th>url3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271355</th>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271356</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271357</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271358</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271359</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271360 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                              title  \\\n",
       "0       0195153448                                Classical Mythology   \n",
       "1       0002005018                                       Clara Callan   \n",
       "2       0060973129                               Decision in Normandy   \n",
       "3       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4       0393045218                             The Mummies of Urumchi   \n",
       "...            ...                                                ...   \n",
       "271355  0440400988                         There's a Bat in Bunk Five   \n",
       "271356  0525447644                            From One to One Hundred   \n",
       "271357  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271358  0192126040                        Republic (World's Classics)   \n",
       "271359  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                      author  year  \\\n",
       "0         Mark P. O. Morford  2002   \n",
       "1       Richard Bruce Wright  2001   \n",
       "2               Carlo D'Este  1991   \n",
       "3           Gina Bari Kolata  1999   \n",
       "4            E. J. W. Barber  1999   \n",
       "...                      ...   ...   \n",
       "271355        Paula Danziger  1988   \n",
       "271356            Teri Sloat  1991   \n",
       "271357      Christine Wicker  2004   \n",
       "271358                 Plato  1996   \n",
       "271359   Christopher  Biffle  2000   \n",
       "\n",
       "                                               publisher  \\\n",
       "0                                Oxford University Press   \n",
       "1                                  HarperFlamingo Canada   \n",
       "2                                        HarperPerennial   \n",
       "3                                   Farrar Straus Giroux   \n",
       "4                             W. W. Norton &amp; Company   \n",
       "...                                                  ...   \n",
       "271355                   Random House Childrens Pub (Mm)   \n",
       "271356                                      Dutton Books   \n",
       "271357                                HarperSanFrancisco   \n",
       "271358                           Oxford University Press   \n",
       "271359  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                                     url1  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                                     url2  \\\n",
       "0       http://images.amazon.com/images/P/0195153448.0...   \n",
       "1       http://images.amazon.com/images/P/0002005018.0...   \n",
       "2       http://images.amazon.com/images/P/0060973129.0...   \n",
       "3       http://images.amazon.com/images/P/0374157065.0...   \n",
       "4       http://images.amazon.com/images/P/0393045218.0...   \n",
       "...                                                   ...   \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                                     url3  \n",
       "0       http://images.amazon.com/images/P/0195153448.0...  \n",
       "1       http://images.amazon.com/images/P/0002005018.0...  \n",
       "2       http://images.amazon.com/images/P/0060973129.0...  \n",
       "3       http://images.amazon.com/images/P/0374157065.0...  \n",
       "4       http://images.amazon.com/images/P/0393045218.0...  \n",
       "...                                                   ...  \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...  \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...  \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...  \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...  \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...  \n",
       "\n",
       "[271360 rows x 8 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data_dump\", \"BX-Books.csv\")\n",
    "books = pd.read_csv(data_path, encoding=\"ISO-8859-1\", sep=\";\", on_bad_lines=\"warn\")\n",
    "books.rename(columns = {'Book-Title': 'title', \n",
    "              'Book-Author': \"author\", \n",
    "              'Year-Of-Publication': \"year\", \n",
    "              'Publisher': \"publisher\", \n",
    "              \"Image-URL-S\":\"url1\", \n",
    "              \"Image-URL-M\": \"url2\", \n",
    "              \"Image-URL-L\": \"url3\"}, inplace=True)\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150788\n"
     ]
    }
   ],
   "source": [
    "# just to get problematic rows numbers:\n",
    "missing_rows = []\n",
    "with open(data_path) as csv_file:\n",
    "    reader = csv.reader(csv_file, delimiter=';')\n",
    "    for e, row in enumerate(reader):\n",
    "        if (len(row) != 8):\n",
    "            missing_rows.append(e)\n",
    "\n",
    "# load rows in easier format:\n",
    "f=open(data_path)\n",
    "lines=f.readlines()\n",
    "\n",
    "# parse these problematic rows:\n",
    "missing_rows_content = []\n",
    "for row_number in missing_rows:\n",
    "    row_content = lines[row_number].split(\";\")\n",
    "    row_dict = {}\n",
    "    try:\n",
    "        row_dict[\"year\"] = eval(row_content[-5])\n",
    "    except SyntaxError:\n",
    "        print(row_number)\n",
    "        continue     \n",
    "    row_dict[\"ISBN\"] = eval(row_content[0])\n",
    "    row_dict[\"title\"] = re.sub('[^A-Za-z0-9]+', ' ', row_content[1])\n",
    "    row_dict[\"url3\"] = eval(row_content[-1])\n",
    "    row_dict[\"url2\"] = eval(row_content[-2])\n",
    "    row_dict[\"url1\"] = eval(row_content[-3])\n",
    "    row_dict[\"publisher\"] = eval(row_content[-4])\n",
    "    row_dict[\"author\"] = eval(row_content[-6])\n",
    "    missing_rows_content.append(row_dict)\n",
    "\n",
    "missing_rows_df = pd.DataFrame(missing_rows_content)\n",
    "books = pd.concat([missing_rows_df.reset_index(drop=True), books.reset_index(drop=True)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year         object\n",
      "ISBN         object\n",
      "title        object\n",
      "url3         object\n",
      "url2         object\n",
      "url1         object\n",
      "publisher    object\n",
      "author       object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "year         0\n",
      "ISBN         0\n",
      "title        0\n",
      "url3         3\n",
      "url2         0\n",
      "url1         0\n",
      "publisher    2\n",
      "author       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# last column missings = some rows might not have parse ok\n",
    "print(books.dtypes)\n",
    "print(\"\\n\")\n",
    "print(books.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>title</th>\n",
       "      <th>url3</th>\n",
       "      <th>url2</th>\n",
       "      <th>url1</th>\n",
       "      <th>publisher</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209538</th>\n",
       "      <td>DK Publishing Inc</td>\n",
       "      <td>078946697X</td>\n",
       "      <td>DK Readers: Creating the X-Men, How It All Beg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.amazon.com/images/P/078946697X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/078946697X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/078946697X.0...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220731</th>\n",
       "      <td>Gallimard</td>\n",
       "      <td>2070426769</td>\n",
       "      <td>Peuple du ciel, suivi de 'Les Bergers\\\";Jean-M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.amazon.com/images/P/2070426769.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/2070426769.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/2070426769.0...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221678</th>\n",
       "      <td>DK Publishing Inc</td>\n",
       "      <td>0789466953</td>\n",
       "      <td>DK Readers: Creating the X-Men, How Comic Book...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://images.amazon.com/images/P/0789466953.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0789466953.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0789466953.0...</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year        ISBN  \\\n",
       "209538  DK Publishing Inc  078946697X   \n",
       "220731          Gallimard  2070426769   \n",
       "221678  DK Publishing Inc  0789466953   \n",
       "\n",
       "                                                    title url3  \\\n",
       "209538  DK Readers: Creating the X-Men, How It All Beg...  NaN   \n",
       "220731  Peuple du ciel, suivi de 'Les Bergers\\\";Jean-M...  NaN   \n",
       "221678  DK Readers: Creating the X-Men, How Comic Book...  NaN   \n",
       "\n",
       "                                                     url2  \\\n",
       "209538  http://images.amazon.com/images/P/078946697X.0...   \n",
       "220731  http://images.amazon.com/images/P/2070426769.0...   \n",
       "221678  http://images.amazon.com/images/P/0789466953.0...   \n",
       "\n",
       "                                                     url1  \\\n",
       "209538  http://images.amazon.com/images/P/078946697X.0...   \n",
       "220731  http://images.amazon.com/images/P/2070426769.0...   \n",
       "221678  http://images.amazon.com/images/P/0789466953.0...   \n",
       "\n",
       "                                                publisher author  \n",
       "209538  http://images.amazon.com/images/P/078946697X.0...   2000  \n",
       "220731  http://images.amazon.com/images/P/2070426769.0...   2003  \n",
       "221678  http://images.amazon.com/images/P/0789466953.0...   2000  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows that have parsed wrong\n",
    "books.loc[books[\"url3\"].isna(), :]\n",
    "# books.loc[books[\"ISBN\"]==\"0789466953\", :]\n",
    "# books.loc[books[\"ISBN\"]==\"078946697X\", :]\n",
    "# books.loc[books[\"ISBN\"]==\"2070426769\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year         0\n",
       "ISBN         0\n",
       "title        0\n",
       "url3         0\n",
       "url2         0\n",
       "url1         0\n",
       "publisher    2\n",
       "author       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# they are duplicates, so drop, did the rest parse ok?\n",
    "books.drop(books.loc[books['url3'].isna()].index, inplace=True)\n",
    "books.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some ISBN contain X, they all need to be in same format for merge\n",
    "books[\"ISBN\"] = books[\"ISBN\"].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant variables\n",
    "books.drop(columns=[\"url1\", \"url2\", \"url3\", \"publisher\", \"year\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISBN</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000913154</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0812515560</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0812514440</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0812514459</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0812514475</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author\n",
       "ISBN              \n",
       "0000913154       1\n",
       "0812515560       1\n",
       "0812514440       1\n",
       "0812514459       1\n",
       "0812514475       1"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is ISBN unique?\n",
    "books[[\"ISBN\", \"author\"]].groupby(\"ISBN\").nunique().sort_values(\"author\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Selected Poems</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Little Women</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wuthering Heights</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventures of Huckleberry Finn</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dracula</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Secret Garden</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jane Eyre</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pride and Prejudice</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Night Before Christmas</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Great Expectations</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ISBN\n",
       "title                               \n",
       "Selected Poems                    27\n",
       "Little Women                      24\n",
       "Wuthering Heights                 21\n",
       "Adventures of Huckleberry Finn    20\n",
       "Dracula                           20\n",
       "The Secret Garden                 20\n",
       "Jane Eyre                         19\n",
       "Pride and Prejudice               18\n",
       "The Night Before Christmas        18\n",
       "Great Expectations                17"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most old popular books = reprints\n",
    "books[[\"title\", \"ISBN\"]].groupby(\"title\").nunique().sort_values(\"ISBN\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Selected Poems</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dinosaurs</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Gift</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Secret</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Promise</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Masquerade</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Best Friends</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Secrets</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Journey</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Psychology</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                author\n",
       "title                 \n",
       "Selected Poems      25\n",
       "Dinosaurs           12\n",
       "The Gift            12\n",
       "The Secret          11\n",
       "The Promise         11\n",
       "Masquerade          11\n",
       "Best Friends        11\n",
       "Secrets             11\n",
       "Journey             10\n",
       "Psychology          10"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is title unique?\n",
    "books[[\"title\", \"author\"]].groupby(\"title\").nunique().sort_values(\"author\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-137-26f76e3b9c46>:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  books.loc[books.title.str.lower().str.contains(pat='lord of the rings') & books.author.str.lower().str.replace('\\W', '').str.contains(pat='jrrtolkien'), \"title\"] = \"The Lord of the Rings\"\n"
     ]
    }
   ],
   "source": [
    "# just because it was book in the task but this needs to be done for other titles too\n",
    "# bottlenect of the whole analysis!\n",
    "# solution probably includes NLP like get all titles together, filter out common words across authors, ?\n",
    "books.loc[books.title.str.lower().str.contains(pat='lord of the rings') & books.author.str.lower().str.replace('\\W', '').str.contains(pat='jrrtolkien'), \"title\"] = \"The Lord of the Rings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-139-63e8d78fb435>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  books[\"authortitle\"] = books[\"author\"].str.lower().str.replace('\\W', '') + books[\"title\"].str.lower().str.replace('\\W', '')\n"
     ]
    }
   ],
   "source": [
    "# new unique (in the future) identifier\n",
    "books[\"authortitle\"] = books[\"author\"].str.lower().str.replace('\\W', '') + books[\"title\"].str.lower().str.replace('\\W', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connect the datasets:\n",
    "- merge all on ISBN (inner) and user_ID (not inner)\n",
    "- should age be included in making recommendations? spearman correlations between rating and age separately for every book that has at least 50 ratings, then median of absolute values => low value = no \n",
    "- ISBN can't be used for recommender so new identifier created as concatenation of author and title\n",
    "- keep only max rating of user_ID for given authortitle identifier (users rated different editions)\n",
    "- drop books with less than 5 ratings (arbitrary number, should be part of pipeline)\n",
    "- make sparse pivot and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISBN not matched: 0385258259, 15655122046, 0140260676 - search in books.csv didnt find them either\n",
    "# reprints have different ISBN\n",
    "# from this code df[[\"ISBN\", \"rating\"]].groupby([\"ISBN\"]).count().sort_values(\"rating\", ascending=False).reset_index().head(10).merge(books[[\"ISBN\", \"title\"]], on=\"ISBN\")\n",
    "df = books.merge(ratings, on=\"ISBN\", how=\"inner\")\n",
    "df = df.merge(users, on=\"user_ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07752263788555638"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# does age play role? No.\n",
    "corr_df=df.loc[:,[\"rating\", \"Age\", \"authortitle\"]].groupby(\"authortitle\").corr(\"spearman\").reset_index(drop=False)\n",
    "corr_df = corr_df.loc[corr_df[\"level_1\"]==\"Age\", :]\n",
    "\n",
    "counts_df = df.loc[:,[\"rating\", \"Age\", \"authortitle\"]].groupby(\"authortitle\").count().reset_index(drop=False)\n",
    "corr_df = corr_df.loc[corr_df[\"authortitle\"].isin(counts_df.loc[counts_df[\"Age\"]>50, \"authortitle\"]), \"rating\"]\n",
    "corr_df.abs().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max in ISBN has no meaning so just choose one, choose max rating\n",
    "df = df[[\"authortitle\",\"ISBN\", \"rating\", \"user_ID\"]].groupby([\"authortitle\", \"user_ID\"]).max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop books with less than 5 ratings, probably will drop more in future analysis\n",
    "ratings_info = df[[\"rating\", \"authortitle\"]].groupby(\"authortitle\").count().reset_index(drop=False)\n",
    "df = df.loc[df[\"authortitle\"].isin(ratings_info.loc[ratings_info[\"rating\"] >=5, \"authortitle\"]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot=df.pivot(index=\"user_ID\", columns=\"authortitle\", values=\"rating\")\n",
    "df_pivot=df_pivot.fillna(0)\n",
    "pivot_sparse = csr_matrix(df_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[[\"authortitle\", \"author\", \"title\"]].groupby(\"authortitle\").min().reset_index()\n",
    "books[\"is_analysed\"] = 0\n",
    "books.loc[books[\"authortitle\"].isin(df_pivot.columns), \"is_analysed\"] = 1\n",
    "books.to_csv(\"books_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"df_columns.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(df_pivot.columns, output_file)\n",
    "with open(r\"df_index.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(df_pivot.index, output_file)\n",
    "with open(r\"df_pivot_sparse.pickle\", \"wb\") as output_file:\n",
    "    pickle.dump(pivot_sparse, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
